{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue\">Perform Grid Search on Decision Tree to find optimal set of hyperparameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 3], 'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "# define a dictionary of hyperparameters and a list of options for each one to test for the optimal solution\n",
    "params = {\n",
    "    'min_samples_split': [2, 3], \n",
    "    'max_leaf_nodes': list(range(2, 31)),\n",
    "}\n",
    "clf = GridSearchCV(tree, params)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 18, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = clf.best_estimator_\n",
    "best_params = clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_tree.predict(X_test)\n",
    "accuracy_score = np.mean(y_pred == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue\">Grow a Random Forest</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training data splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\clayton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=1000, train_size=100) # test_size becomes the complement of train_size\n",
    "num_splits = splitter.get_n_splits(X_train)\n",
    "num_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 1000-tree forest, each tree trained on a 100-instance subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988112500000001"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtree = np.vectorize(DecisionTreeClassifier)\n",
    "forest = np.empty((1, num_splits), dtype=object)\n",
    "forest[:] = DecisionTreeClassifier(\n",
    "    max_leaf_nodes=best_params['max_leaf_nodes'], \n",
    "    min_samples_split=best_params['min_samples_split']\n",
    ") \n",
    "accuracy_scores = np.empty((1, num_splits), dtype=np.dtype('float'))\n",
    "i = 0\n",
    "for train, test in splitter.split(X_train):\n",
    "    X_train_sub = X[train] # where train is an array containing the indices to extract from X\n",
    "    y_train_sub = y[train]\n",
    "    forest[0, i].fit(X_train_sub, y_train_sub)\n",
    "    X_test_sub = X[test]\n",
    "    y_test_sub = y[test]\n",
    "    y_pred = forest[0, i].predict(X_test_sub)\n",
    "    accuracy_scores[0, i] = np.mean(y_pred == y_test_sub)\n",
    "    i+=1\n",
    "\n",
    "forest_avg_accuracy = np.mean(accuracy_scores)\n",
    "forest_avg_accuracy # ~80% accuracy over 1000 trees trained on 100 subsets, which is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred = np.empty((num_splits, len(X_test)), dtype=np.dtype('int'))\n",
    "for index, tree in enumerate(forest[0]):\n",
    "    y_pred[index] = tree.predict(X_test)\n",
    "\n",
    "y_pred_majority, n_votes = mode(y_pred, axis=0)\n",
    "y_pred_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred_majority == y_test) # accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of this random forests is correct and the score is reasonable, but unusual how it is lower than the first model. (???)  \n",
    "However, it does show that the random forests does work better than a single tree in the forest, on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
